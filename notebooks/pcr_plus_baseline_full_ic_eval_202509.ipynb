{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11b4903d",
   "metadata": {},
   "source": [
    "# PCR + Baseline 30m IC Evaluation\n",
    "\n",
    "This notebook evaluates two signals at the same entry times:\n",
    "\n",
    "- `baseline`: `data/processed/futures_only_signal`\n",
    "- `baseline_plus_pcr`: baseline signal + PCR signal from `data/processed/index_russell_pcr_signal_30m`\n",
    "\n",
    "It computes:\n",
    "\n",
    "1. Cross-sectional IC by date\n",
    "2. IC by ticker\n",
    "3. IC by ticker by year\n",
    "\n",
    "All calculations use the same entry-time sample and realized unhedged ADR return from entry-mid to daily close.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4f6a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', 200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a8cd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path('data') if Path('data/raw/adr_info.csv').exists() else Path('../data')\n",
    "assert (DATA_DIR / 'raw' / 'adr_info.csv').exists(), 'Could not resolve data directory.'\n",
    "\n",
    "PCR_SIGNAL_DIR = DATA_DIR / 'processed' / 'index_russell_pcr_signal'\n",
    "BASELINE_SIGNAL_DIR = DATA_DIR / 'processed' / 'futures_only_signal'\n",
    "ADR_NBBO_DIR = DATA_DIR / 'raw' / 'adrs' / 'bbo-1m' / 'nbbo'\n",
    "ADR_CLOSE_FILE = DATA_DIR / 'raw' / 'adrs' / 'adr_PX_LAST_adjust_none.csv'\n",
    "\n",
    "ENTRY_TIMES = ['13:00', '13:30', '14:00', '14:30', '15:00', '15:30']\n",
    "MIN_OBS_TICKER = 30\n",
    "MIN_OBS_CROSS_SECTION = 8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cd9b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _safe_corr(x: pd.Series, y: pd.Series, min_obs: int = 2) -> float:\n",
    "    z = pd.concat([x, y], axis=1).dropna()\n",
    "    if len(z) < min_obs:\n",
    "        return np.nan\n",
    "    if z.iloc[:, 0].std() == 0 or z.iloc[:, 1].std() == 0:\n",
    "        return np.nan\n",
    "    return float(z.iloc[:, 0].corr(z.iloc[:, 1]))\n",
    "\n",
    "\n",
    "def _coerce_datetime_index(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Return a copy with a DatetimeIndex when possible.\"\"\"\n",
    "    out = df.copy()\n",
    "    if isinstance(out.index, pd.DatetimeIndex):\n",
    "        return out\n",
    "\n",
    "    candidate_cols = ['timestamp', 'datetime', 'date_time', 'index', '__index_level_0__']\n",
    "    for col in candidate_cols:\n",
    "        if col in out.columns:\n",
    "            ts = pd.to_datetime(out[col], errors='coerce')\n",
    "            if ts.notna().any():\n",
    "                out = out.loc[ts.notna()].copy()\n",
    "                out.index = pd.DatetimeIndex(ts[ts.notna()])\n",
    "                return out\n",
    "\n",
    "    idx = pd.to_datetime(out.index, errors='coerce')\n",
    "    if idx.notna().any():\n",
    "        out = out.loc[idx.notna()].copy()\n",
    "        out.index = pd.DatetimeIndex(idx[idx.notna()])\n",
    "        return out\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def _extract_signal_at_times(signal_df: pd.DataFrame, entry_times):\n",
    "    signal_df = _coerce_datetime_index(signal_df)\n",
    "    if not isinstance(signal_df.index, pd.DatetimeIndex) or 'signal' not in signal_df.columns:\n",
    "        return {t: pd.Series(dtype=float) for t in entry_times}\n",
    "\n",
    "    out = {}\n",
    "    for t in entry_times:\n",
    "        h, m = map(int, t.split(':'))\n",
    "        s = signal_df.loc[(signal_df.index.hour == h) & (signal_df.index.minute == m), 'signal']\n",
    "        if len(s) == 0:\n",
    "            out[t] = pd.Series(dtype=float)\n",
    "            continue\n",
    "        idx = s.index.tz_localize(None).normalize() if s.index.tz is not None else s.index.normalize()\n",
    "        out[t] = pd.Series(s.values, index=idx).groupby(level=0).first().sort_index()\n",
    "    return out\n",
    "\n",
    "\n",
    "def _extract_nbbo_mid_at_times(nbbo_df: pd.DataFrame, entry_times):\n",
    "    nbbo_df = _coerce_datetime_index(nbbo_df)\n",
    "    if not isinstance(nbbo_df.index, pd.DatetimeIndex):\n",
    "        return {t: pd.Series(dtype=float) for t in entry_times}\n",
    "\n",
    "    mid = (nbbo_df['nbbo_bid'] + nbbo_df['nbbo_ask']) / 2\n",
    "    out = {}\n",
    "    for t in entry_times:\n",
    "        s = mid.between_time(t, t)\n",
    "        if len(s) == 0:\n",
    "            out[t] = pd.Series(dtype=float)\n",
    "            continue\n",
    "        idx = s.index.tz_localize(None).normalize() if s.index.tz is not None else s.index.normalize()\n",
    "        out[t] = pd.Series(s.values, index=idx).groupby(level=0).first().sort_index()\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c917361",
   "metadata": {},
   "outputs": [],
   "source": [
    "adr_info = pd.read_csv(DATA_DIR / 'raw' / 'adr_info.csv')\n",
    "adr_info['ticker'] = adr_info['adr'].str.split().str[0]\n",
    "all_tickers = sorted(adr_info['ticker'].unique())\n",
    "\n",
    "pcr_tickers = sorted([p.name.split('=', 1)[1] for p in PCR_SIGNAL_DIR.glob('ticker=*') if p.is_dir()])\n",
    "baseline_tickers = sorted([p.name.split('=', 1)[1] for p in BASELINE_SIGNAL_DIR.glob('ticker=*') if p.is_dir()])\n",
    "\n",
    "# Evaluate on common tickers where both signals exist.\n",
    "tickers = sorted(set(all_tickers).intersection(pcr_tickers).intersection(baseline_tickers))\n",
    "print(f'Tickers in evaluation universe: {len(tickers)}')\n",
    "\n",
    "close_df = pd.read_csv(ADR_CLOSE_FILE, index_col=0, parse_dates=True)\n",
    "close_df.index = pd.DatetimeIndex(close_df.index).normalize()\n",
    "close_df = close_df.reindex(columns=tickers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15545cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "\n",
    "for ticker in tqdm(tickers, desc='Building panel'):\n",
    "    pcr_path = PCR_SIGNAL_DIR / f'ticker={ticker}' / 'data.parquet'\n",
    "    base_path = BASELINE_SIGNAL_DIR / f'ticker={ticker}' / 'data.parquet'\n",
    "    nbbo_path = ADR_NBBO_DIR / f'ticker={ticker}' / 'data.parquet'\n",
    "\n",
    "    if not (pcr_path.exists() and base_path.exists() and nbbo_path.exists()):\n",
    "        continue\n",
    "\n",
    "    pcr_df = pd.read_parquet(pcr_path)\n",
    "    base_df = pd.read_parquet(base_path)\n",
    "    nbbo_df = pd.read_parquet(nbbo_path, columns=['nbbo_bid', 'nbbo_ask'])\n",
    "\n",
    "    pcr_by_time = _extract_signal_at_times(pcr_df, ENTRY_TIMES)\n",
    "    base_by_time = _extract_signal_at_times(base_df, ENTRY_TIMES)\n",
    "    entry_mid_by_time = _extract_nbbo_mid_at_times(nbbo_df, ENTRY_TIMES)\n",
    "\n",
    "    if ticker not in close_df.columns:\n",
    "        continue\n",
    "    daily_close = close_df[ticker].dropna()\n",
    "\n",
    "    for et in ENTRY_TIMES:\n",
    "        pcr_s = pcr_by_time.get(et, pd.Series(dtype=float))\n",
    "        base_s = base_by_time.get(et, pd.Series(dtype=float))\n",
    "        entry_mid = entry_mid_by_time.get(et, pd.Series(dtype=float))\n",
    "\n",
    "        if len(pcr_s) == 0 or len(base_s) == 0 or len(entry_mid) == 0:\n",
    "            continue\n",
    "\n",
    "        common = pcr_s.index.intersection(base_s.index).intersection(entry_mid.index).intersection(daily_close.index)\n",
    "        if len(common) == 0:\n",
    "            continue\n",
    "\n",
    "        p = pcr_s.loc[common].astype(float)\n",
    "        b = base_s.loc[common].astype(float)\n",
    "        em = entry_mid.loc[common].astype(float)\n",
    "        dc = daily_close.loc[common].astype(float)\n",
    "\n",
    "        # Realized unhedged ADR return from entry mid to daily close.\n",
    "        r = (dc / em) - 1.0\n",
    "\n",
    "        panel = pd.DataFrame({\n",
    "            'date': common,\n",
    "            'ticker': ticker,\n",
    "            'entry_time': et,\n",
    "            'baseline_signal': b.values,\n",
    "            'pcr_signal': p.values,\n",
    "            'realized_return': r.values,\n",
    "        }).dropna()\n",
    "\n",
    "        if len(panel) == 0:\n",
    "            continue\n",
    "\n",
    "        panel['baseline_plus_pcr_signal'] = panel['baseline_signal'] + panel['pcr_signal']\n",
    "        rows.append(panel)\n",
    "\n",
    "panel_df = pd.concat(rows, ignore_index=True) if rows else pd.DataFrame()\n",
    "print('Panel rows:', len(panel_df))\n",
    "print('Unique tickers:', panel_df['ticker'].nunique() if len(panel_df) else 0)\n",
    "print('Date range:', panel_df['date'].min() if len(panel_df) else None, '->', panel_df['date'].max() if len(panel_df) else None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfb2934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Cross-sectional IC by date (pooled across entry times)\n",
    "def cs_ic_by_group(df, signal_col, ret_col, min_obs=MIN_OBS_CROSS_SECTION):\n",
    "    out = {}\n",
    "    for key, g in df.groupby('date'):\n",
    "        c = _safe_corr(g[signal_col], g[ret_col], min_obs=min_obs)\n",
    "        out[key] = c\n",
    "    return pd.Series(out).sort_index()\n",
    "\n",
    "\n",
    "cs_date_baseline = cs_ic_by_group(panel_df, 'baseline_signal', 'realized_return')\n",
    "cs_date_plus_pcr = cs_ic_by_group(panel_df, 'baseline_plus_pcr_signal', 'realized_return')\n",
    "\n",
    "cs_date = pd.DataFrame({\n",
    "    'baseline_cs_ic': cs_date_baseline,\n",
    "    'baseline_plus_pcr_cs_ic': cs_date_plus_pcr,\n",
    "})\n",
    "cs_date['improvement'] = cs_date['baseline_plus_pcr_cs_ic'] - cs_date['baseline_cs_ic']\n",
    "\n",
    "print('Cross-sectional IC by date (head):')\n",
    "display(cs_date.head())\n",
    "print('Mean CS IC by date:')\n",
    "display(cs_date.mean(numeric_only=True).to_frame('mean').T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0059d5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: cross-sectional IC by (date, entry_time)\n",
    "def cs_ic_by_date_time(df, signal_col, ret_col, min_obs=MIN_OBS_CROSS_SECTION):\n",
    "    out = {}\n",
    "    for (d, et), g in df.groupby(['date', 'entry_time']):\n",
    "        out[(d, et)] = _safe_corr(g[signal_col], g[ret_col], min_obs=min_obs)\n",
    "    idx = pd.MultiIndex.from_tuples(list(out.keys()), names=['date', 'entry_time']) if out else pd.MultiIndex.from_tuples([], names=['date', 'entry_time'])\n",
    "    return pd.Series(list(out.values()), index=idx).sort_index()\n",
    "\n",
    "cs_dt_baseline = cs_ic_by_date_time(panel_df, 'baseline_signal', 'realized_return')\n",
    "cs_dt_plus_pcr = cs_ic_by_date_time(panel_df, 'baseline_plus_pcr_signal', 'realized_return')\n",
    "\n",
    "cs_dt = pd.DataFrame({\n",
    "    'baseline_cs_ic': cs_dt_baseline,\n",
    "    'baseline_plus_pcr_cs_ic': cs_dt_plus_pcr,\n",
    "})\n",
    "cs_dt['improvement'] = cs_dt['baseline_plus_pcr_cs_ic'] - cs_dt['baseline_cs_ic']\n",
    "\n",
    "print('Cross-sectional IC by (date, entry_time), sample:')\n",
    "display(cs_dt.head(12))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1d3689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) IC by ticker (time-series IC across all dates + entry times)\n",
    "ticker_rows = []\n",
    "for ticker, g in panel_df.groupby('ticker'):\n",
    "    base_ic = _safe_corr(g['baseline_signal'], g['realized_return'], min_obs=MIN_OBS_TICKER)\n",
    "    plus_ic = _safe_corr(g['baseline_plus_pcr_signal'], g['realized_return'], min_obs=MIN_OBS_TICKER)\n",
    "    ticker_rows.append({\n",
    "        'ticker': ticker,\n",
    "        'n_obs': len(g),\n",
    "        'baseline_ic': base_ic,\n",
    "        'baseline_plus_pcr_ic': plus_ic,\n",
    "        'improvement': plus_ic - base_ic if pd.notna(base_ic) and pd.notna(plus_ic) else np.nan,\n",
    "    })\n",
    "\n",
    "ticker_ic = pd.DataFrame(ticker_rows).set_index('ticker').sort_values('improvement', ascending=False)\n",
    "print('IC by ticker:')\n",
    "display(ticker_ic)\n",
    "print('Mean ticker IC:')\n",
    "display(ticker_ic[['baseline_ic', 'baseline_plus_pcr_ic', 'improvement']].mean(numeric_only=True).to_frame('mean').T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37a105e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) IC by ticker by year\n",
    "panel_df['year'] = pd.DatetimeIndex(panel_df['date']).year\n",
    "\n",
    "ty_rows = []\n",
    "for (ticker, year), g in panel_df.groupby(['ticker', 'year']):\n",
    "    base_ic = _safe_corr(g['baseline_signal'], g['realized_return'], min_obs=MIN_OBS_TICKER)\n",
    "    plus_ic = _safe_corr(g['baseline_plus_pcr_signal'], g['realized_return'], min_obs=MIN_OBS_TICKER)\n",
    "    ty_rows.append({\n",
    "        'ticker': ticker,\n",
    "        'year': int(year),\n",
    "        'n_obs': len(g),\n",
    "        'baseline_ic': base_ic,\n",
    "        'baseline_plus_pcr_ic': plus_ic,\n",
    "        'improvement': plus_ic - base_ic if pd.notna(base_ic) and pd.notna(plus_ic) else np.nan,\n",
    "    })\n",
    "\n",
    "ticker_year_ic = pd.DataFrame(ty_rows).sort_values(['ticker', 'year'])\n",
    "print('Ticker-by-year IC (sample):')\n",
    "display(ticker_year_ic.head(50))\n",
    "\n",
    "print('Yearly mean IC across ticker-years:')\n",
    "yearly_summary = ticker_year_ic.groupby('year')[['baseline_ic', 'baseline_plus_pcr_ic', 'improvement']].mean()\n",
    "display(yearly_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4666e4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# CS IC by date cumulative mean\n",
    "cs_date[['baseline_cs_ic', 'baseline_plus_pcr_cs_ic']].expanding().mean().plot(ax=axes[0])\n",
    "axes[0].set_title('Expanding Mean CS IC by Date')\n",
    "axes[0].axhline(0.0, color='gray', linewidth=0.8)\n",
    "\n",
    "# Ticker IC scatter\n",
    "tmp = ticker_ic.dropna(subset=['baseline_ic', 'baseline_plus_pcr_ic'])\n",
    "axes[1].scatter(tmp['baseline_ic'], tmp['baseline_plus_pcr_ic'], alpha=0.7)\n",
    "lims = [\n",
    "    np.nanmin([tmp['baseline_ic'].min(), tmp['baseline_plus_pcr_ic'].min()]),\n",
    "    np.nanmax([tmp['baseline_ic'].max(), tmp['baseline_plus_pcr_ic'].max()]),\n",
    "]\n",
    "axes[1].plot(lims, lims, 'k--', linewidth=1)\n",
    "axes[1].set_xlabel('Baseline IC')\n",
    "axes[1].set_ylabel('Baseline + PCR IC')\n",
    "axes[1].set_title('IC by Ticker')\n",
    "\n",
    "# Yearly improvement bars\n",
    "yearly_summary['improvement'].plot(kind='bar', ax=axes[2], color='steelblue')\n",
    "axes[2].axhline(0.0, color='gray', linewidth=0.8)\n",
    "axes[2].set_title('Yearly Mean IC Improvement (Baseline + PCR - Baseline)')\n",
    "\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f86bf6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save analysis tables for reuse in scripts\n",
    "out_dir = DATA_DIR / 'processed' / 'reports' / 'pcr_plus_baseline_30m_ic'\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "cs_date.to_csv(out_dir / 'cross_sectional_ic_by_date.csv')\n",
    "cs_dt.to_csv(out_dir / 'cross_sectional_ic_by_date_entry_time.csv')\n",
    "ticker_ic.to_csv(out_dir / 'ic_by_ticker.csv')\n",
    "ticker_year_ic.to_csv(out_dir / 'ic_by_ticker_by_year.csv', index=False)\n",
    "\n",
    "print('Saved outputs to:', out_dir)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
